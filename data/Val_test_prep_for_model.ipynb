{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and Test Prediction Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, when, udf, lit\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "from unidecode import unidecode\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark.sql.functions import col, lit, when, udf\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IMDB Prediction\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation_path = '/Users/bognarlili/Big_Data_IMDb-1/data/validation_hidden.csv'\n",
    "test_path = '/Users/bognarlili/Big_Data_IMDb-1/data/test_hidden.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+-------------------+---------+-------+--------------+--------+\n",
      "|_c0|   tconst|        primaryTitle|      originalTitle|startYear|endYear|runtimeMinutes|numVotes|\n",
      "+---+---------+--------------------+-------------------+---------+-------+--------------+--------+\n",
      "|  0|tt0003740|             Cabiria|               NULL|     1914|     \\N|           148|  3452.0|\n",
      "|  1|tt0008663|     A Man There Was|        Terje Vigen|     1917|     \\N|            65|  1882.0|\n",
      "|  3|tt0010307|           J'accuse!|               NULL|     1919|     \\N|           166|  1692.0|\n",
      "| 18|tt0014429|        Safety Last!|       Safety Last!|     1923|     \\N|            74| 19898.0|\n",
      "| 27|tt0015175|Die Nibelungen: S...|               NULL|     1924|     \\N|           143|  5676.0|\n",
      "| 39|tt0016332|       Seven Chances|               NULL|     1925|     \\N|            56|  9914.0|\n",
      "| 61|tt0018737|       Pandora's Box|               NULL|       \\N|   1929|           109| 10475.0|\n",
      "| 65|tt0018839|The Docks of New ...|               NULL|     1928|     \\N|            76|  4339.0|\n",
      "| 71|tt0019421| Steamboat Bill, Jr.|Steamboat Bill, Jr.|     1928|     \\N|            70| 14166.0|\n",
      "| 75|tt0019901|   Woman in the Moon|               NULL|     1929|     \\N|           156|    NULL|\n",
      "| 91|tt0022150|          Le Million|               NULL|     1931|     \\N|            91|  3434.0|\n",
      "| 92|tt0022153|   The Miracle Woman|               NULL|     1931|     \\N|            90|  2013.0|\n",
      "|142|tt0025699|   Randy Rides Alone|               NULL|     1934|     \\N|            52|  1034.0|\n",
      "|153|tt0026725|      Les Misérables|     Les Misérables|     1935|     \\N|           108|  3512.0|\n",
      "|158|tt0027336|    The Lower Depths|      Les bas-fonds|     1936|     \\N|            95|  3194.0|\n",
      "|159|tt0027342|      They Were Five|    La belle équipe|     1936|     \\N|           100|  1202.0|\n",
      "|167|tt0027672| Sisters of the Gion|               NULL|     1936|     \\N|            69|  2621.0|\n",
      "|174|tt0028167|           Rembrandt|          Rembrandt|     1936|     \\N|            85|  1778.0|\n",
      "|178|tt0028313|The Story of Loui...|               NULL|     1936|     \\N|            86|  2705.0|\n",
      "|187|tt0028737|          Confession|         Confession|     1937|     \\N|            87|  1201.0|\n",
      "+---+---------+--------------------+-------------------+---------+-------+--------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/19 21:26:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , tconst, primaryTitle, originalTitle, startYear, endYear, runtimeMinutes, numVotes\n",
      " Schema: _c0, tconst, primaryTitle, originalTitle, startYear, endYear, runtimeMinutes, numVotes\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/bognarlili/Big_Data_IMDb-1/data/validation_hidden.csv\n"
     ]
    }
   ],
   "source": [
    "validation = spark.read.csv(validation_path, header=True, inferSchema=True)\n",
    "test = spark.read.csv(test_path, header=True, inferSchema=True)\n",
    "validation.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+-------------------+---------+-------+--------------+--------+\n",
      "|_c0|   tconst|        primaryTitle|      originalTitle|startYear|endYear|runtimeMinutes|numVotes|\n",
      "+---+---------+--------------------+-------------------+---------+-------+--------------+--------+\n",
      "| 22|tt0014972| He Who Gets Slapped|He Who Gets Slapped|     1924|     \\N|            95|  3654.0|\n",
      "| 23|tt0015016|      The Iron Horse|               NULL|     1924|     \\N|           150|  2136.0|\n",
      "| 26|tt0015174|Die Nibelungen: K...|               NULL|     1924|     \\N|           129|  4341.0|\n",
      "| 28|tt0015214|             At 3:25|               NULL|       \\N|   1925|            59|  1724.0|\n",
      "| 34|tt0015863|             Go West|               NULL|     1925|     \\N|            69|  4188.0|\n",
      "| 40|tt0016481|             Variety|            Varieté|     1925|     \\N|           104|  1188.0|\n",
      "| 46|tt0017136|          Metropolis|               NULL|     1927|     \\N|           153|168372.0|\n",
      "| 66|tt0018876|   The Farmer's Wife|               NULL|     1928|     \\N|           100|  2741.0|\n",
      "| 67|tt0019074| Laugh, Clown, Laugh|Laugh, Clown, Laugh|     1928|     \\N|            73|  1934.0|\n",
      "| 84|tt0021730|           The Champ|               NULL|     1931|     \\N|            86|  3057.0|\n",
      "| 87|tt0022074|The Smiling Lieut...|               NULL|     1931|     \\N|            93|  3632.0|\n",
      "| 88|tt0022080|               Limit|               NULL|     1931|     \\N|           114|    NULL|\n",
      "|103|tt0023241|         Movie Crazy|               NULL|     1932|     \\N|            84|    NULL|\n",
      "|111|tt0023775|           Baby Face|               NULL|     1933|     \\N|            71|  6775.0|\n",
      "|115|tt0023940|   Design for Living|  Design for Living|     1933|     \\N|            91|    NULL|\n",
      "|120|tt0024028|    Footlight Parade|   Footlight Parade|     1933|     \\N|           104|  5285.0|\n",
      "|126|tt0024240|      Lády fớr á Dáy|     Lady for a Day|     1933|     \\N|            96|    NULL|\n",
      "|143|tt0025746| The Scarlet Empress|               NULL|     1934|     \\N|           104|  6400.0|\n",
      "|144|tt0025862| Tarzan and His Mate|               NULL|     1934|     \\N|           104|  5033.0|\n",
      "|147|tt0025929|A Story of Floati...| Ukikusa monogatari|     1934|     \\N|            86|  3032.0|\n",
      "+---+---------+--------------------+-------------------+---------+-------+--------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/19 21:26:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , tconst, primaryTitle, originalTitle, startYear, endYear, runtimeMinutes, numVotes\n",
      " Schema: _c0, tconst, primaryTitle, originalTitle, startYear, endYear, runtimeMinutes, numVotes\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/bognarlili/Big_Data_IMDb-1/data/test_hidden.csv\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the validation and the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.validation_df = None\n",
    "        self.test_df = None\n",
    "        \n",
    "       \n",
    "        self.expected_columns = [\n",
    "            'tconst', 'movie_title', 'year', 'numVotes', 'genre', \n",
    "            'content_rating', 'production_company', 'tomatometer_status', \n",
    "            'tomatometer_rating', 'audience_status', 'audience_rating', \n",
    "            'review_score', 'like_count', 'label_int', 'reviews', 'review_lemmatized'\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        self.fill_values = {\n",
    "            'movie_title': 'Unknown',\n",
    "            'genre': 'Unknown',\n",
    "            'content_rating': 'Unknown',\n",
    "            'production_company': 'Unknown',\n",
    "            'tomatometer_status': -1,\n",
    "            'tomatometer_rating': -1,\n",
    "            'audience_status': -1,\n",
    "            'audience_rating': -1,\n",
    "            'review_score': 'Unknown',\n",
    "            'like_count': -1,\n",
    "            'label_int': -1,\n",
    "            'reviews': 'Unknown',\n",
    "            'review_lemmatized': 'Unknown'\n",
    "        }\n",
    "        \n",
    "        #  (special characters removal)\n",
    "        self.normalize_text_udf = udf(self.normalize_text, StringType())\n",
    "\n",
    "    # Validation Data\n",
    "    def load_validation_data(self):\n",
    "        path = \"data/\"\n",
    "        validation_df = pd.read_csv(f\"{path}/validation_hidden.csv\", index_col=[0])\n",
    "        validation_df = validation_df.drop(columns=\"runtimeMinutes\")\n",
    "\n",
    "        # Handle \\N values as None\n",
    "        self.validation_df = spark.createDataFrame(validation_df).replace(to_replace='\\\\N', value=None)\n",
    "        \n",
    "        # Rename primaryTitle \n",
    "        self.validation_df = self.validation_df.withColumnRenamed(\"primaryTitle\", \"movie_title\")\n",
    "        print(\" Validation data loaded\")\n",
    "\n",
    "    # Test Data\n",
    "    def load_test_data(self):\n",
    "        path = \"data/\"\n",
    "        test_df = pd.read_csv(f\"{path}/test_hidden.csv\", index_col=[0])\n",
    "        test_df = test_df.drop(columns=\"runtimeMinutes\")\n",
    "\n",
    "        # Handle \\N values as None\n",
    "        self.test_df = spark.createDataFrame(test_df).replace(to_replace='\\\\N', value=None)\n",
    "        \n",
    "        # Rename primaryTitle → movie_title\n",
    "        self.test_df = self.test_df.withColumnRenamed(\"primaryTitle\", \"movie_title\")\n",
    "        print(\"Test data loaded\")\n",
    "\n",
    "    #Handle Year Data\n",
    "    def handle_years(self, df):\n",
    "        if 'startYear' in df.columns and 'endYear' in df.columns:\n",
    "            df = df.withColumn(\"year\", when(col(\"startYear\").isNotNull(), col(\"startYear\"))\n",
    "                               .otherwise(col(\"endYear\")))\n",
    "            df = df.drop(\"startYear\", \"endYear\")\n",
    "        return df\n",
    "\n",
    "    #Normalize Titles\n",
    "    @staticmethod\n",
    "    def normalize_text(text):\n",
    "        if text is None:\n",
    "            return None\n",
    "        return unidecode(text)\n",
    "    \n",
    "    def clean_titles(self, df):\n",
    "        df = df.withColumn(\"movie_title\", self.normalize_text_udf(col(\"movie_title\")))\n",
    "        \n",
    "        if 'originalTitle' in df.columns:\n",
    "            df = df.withColumn(\"originalTitle\", self.normalize_text_udf(col(\"originalTitle\")))\n",
    "            df = df.withColumn(\"movie_title\", \n",
    "                               F.concat_ws(' - ', F.col('movie_title'), F.col('originalTitle')))\n",
    "            df = df.drop(\"originalTitle\")\n",
    "        return df\n",
    "\n",
    "    #add Missing Columns to Match Training Set\n",
    "    def add_missing_columns(self):\n",
    "        missing_columns = [\n",
    "            'label', 'genre', 'content_rating', 'production_company', \n",
    "            'tomatometer_status', 'tomatometer_rating', 'audience_status', \n",
    "            'audience_rating', 'review_score', 'like_count', 'label_int', \n",
    "            'reviews', 'review_lemmatized'\n",
    "        ]\n",
    "        \n",
    "        for col_name in missing_columns:\n",
    "            if col_name not in self.validation_df.columns:\n",
    "                if col_name in ['like_count', 'label_int', 'tomatometer_status', 'tomatometer_rating', \n",
    "                                'audience_status', 'audience_rating']:\n",
    "                    self.validation_df = self.validation_df.withColumn(col_name, lit(-1).cast(IntegerType()))\n",
    "                else:\n",
    "                    self.validation_df = self.validation_df.withColumn(col_name, lit('Unknown').cast(StringType()))\n",
    "\n",
    "            if col_name not in self.test_df.columns:\n",
    "                if col_name in ['like_count', 'label_int', 'tomatometer_status', 'tomatometer_rating', \n",
    "                                'audience_status', 'audience_rating']:\n",
    "                    self.test_df = self.test_df.withColumn(col_name, lit(-1).cast(IntegerType()))\n",
    "                else:\n",
    "                    self.test_df = self.test_df.withColumn(col_name, lit('Unknown').cast(StringType()))\n",
    "\n",
    "        print(\"Missing columns added\")\n",
    "\n",
    "    # Fill Missing Values\n",
    "    def fill_missing_values(self):\n",
    "        for key, value in self.fill_values.items():\n",
    "            if key in self.validation_df.columns:\n",
    "                if isinstance(value, int):\n",
    "                    self.validation_df = self.validation_df.withColumn(key, F.coalesce(col(key), lit(value).cast(IntegerType())))\n",
    "                else:\n",
    "                    self.validation_df = self.validation_df.withColumn(key, F.coalesce(col(key), lit(value).cast(StringType())))\n",
    "\n",
    "            if key in self.test_df.columns:\n",
    "                if isinstance(value, int):\n",
    "                    self.test_df = self.test_df.withColumn(key, F.coalesce(col(key), lit(value).cast(IntegerType())))\n",
    "                else:\n",
    "                    self.test_df = self.test_df.withColumn(key, F.coalesce(col(key), lit(value).cast(StringType())))\n",
    "\n",
    "        print(\" Missing values filled\")\n",
    "\n",
    "    # Reorder Columns to Match Training Set\n",
    "    def reorder_columns(self):\n",
    "        self.validation_df = self.validation_df.select(*[col for col in self.expected_columns if col in self.validation_df.columns])\n",
    "        self.test_df = self.test_df.select(*[col for col in self.expected_columns if col in self.test_df.columns])\n",
    "        print(\"Columns reordered\")\n",
    "\n",
    "    # Write to CSV\n",
    "    def save_to_csv(self, validation_path, test_path):\n",
    "        self.validation_df.coalesce(1).write.csv(validation_path, header=True, mode='overwrite', emptyValue=\"\")\n",
    "        self.test_df.coalesce(1).write.csv(test_path, header=True, mode='overwrite', emptyValue=\"\")\n",
    "        print(\"Final validation and test data saved!\")\n",
    "\n",
    "    # Process Everything\n",
    "    def process(self, validation_path, test_path):\n",
    "        self.load_validation_data()\n",
    "        self.load_test_data()\n",
    "        self.validation_df = self.handle_years(self.validation_df)\n",
    "        self.test_df = self.handle_years(self.test_df)\n",
    "        self.validation_df = self.clean_titles(self.validation_df)\n",
    "        self.test_df = self.clean_titles(self.test_df)\n",
    "        self.add_missing_columns()\n",
    "        self.fill_missing_values()\n",
    "        self.reorder_columns()\n",
    "        self.save_to_csv(validation_path, test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a new column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, validation_df, test_df):\n",
    "        self.validation_df = validation_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        \n",
    "        self.expected_columns = [\n",
    "            'tconst', 'movie_title', 'year', 'numVotes', 'genre', \n",
    "            'content_rating', 'production_company', 'tomatometer_status', \n",
    "            'tomatometer_rating', 'audience_status', 'audience_rating', \n",
    "            'review_score', 'like_count', 'label_int', 'reviews', 'review_lemmatized'\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        self.fill_values = {\n",
    "            'movie_title': 'Unknown',\n",
    "            'genre': 'Unknown',\n",
    "            'content_rating': 'Unknown',\n",
    "            'production_company': 'Unknown',\n",
    "            'tomatometer_status': -1,\n",
    "            'tomatometer_rating': -1,\n",
    "            'audience_status': -1,\n",
    "            'audience_rating': -1,\n",
    "            'review_score': 'Unknown',\n",
    "            'like_count': -1,\n",
    "            'label_int': -1,\n",
    "            'reviews': 'Unknown',\n",
    "            'review_lemmatized': 'Unknown'\n",
    "        }\n",
    "\n",
    "    def add_missing_columns(self):\n",
    "        missing_columns = [\n",
    "            'label', 'genre', 'content_rating', 'production_company', \n",
    "            'tomatometer_status', 'tomatometer_rating', 'audience_status', \n",
    "            'audience_rating', 'review_score', 'like_count', 'label_int', \n",
    "            'reviews', 'review_lemmatized'\n",
    "        ]\n",
    "        \n",
    "        for col_name in missing_columns:\n",
    "            if col_name not in self.validation_df.columns:\n",
    "                if col_name in ['like_count', 'label_int', 'tomatometer_status', 'tomatometer_rating', \n",
    "                                'audience_status', 'audience_rating']:\n",
    "                    self.validation_df = self.validation_df.withColumn(col_name, lit(-1).cast(IntegerType()))\n",
    "                else:\n",
    "                    self.validation_df = self.validation_df.withColumn(col_name, lit('Unknown').cast(StringType()))\n",
    "\n",
    "            if col_name not in self.test_df.columns:\n",
    "                if col_name in ['like_count', 'label_int', 'tomatometer_status', 'tomatometer_rating', \n",
    "                                'audience_status', 'audience_rating']:\n",
    "                    self.test_df = self.test_df.withColumn(col_name, lit(-1).cast(IntegerType()))\n",
    "                else:\n",
    "                    self.test_df = self.test_df.withColumn(col_name, lit('Unknown').cast(StringType()))\n",
    "        \n",
    "        print(\"Missing columns added\")\n",
    "\n",
    "    def fill_missing_values(self):\n",
    "        for key, value in self.fill_values.items():\n",
    "            if key in self.validation_df.columns:\n",
    "                if isinstance(value, int):\n",
    "                    self.validation_df = self.validation_df.withColumn(key, F.coalesce(col(key), lit(value).cast(IntegerType())))\n",
    "                else:\n",
    "                    self.validation_df = self.validation_df.withColumn(key, F.coalesce(col(key), lit(value).cast(StringType())))\n",
    "\n",
    "            if key in self.test_df.columns:\n",
    "                if isinstance(value, int):\n",
    "                    self.test_df = self.test_df.withColumn(key, F.coalesce(col(key), lit(value).cast(IntegerType())))\n",
    "                else:\n",
    "                    self.test_df = self.test_df.withColumn(key, F.coalesce(col(key), lit(value).cast(StringType())))\n",
    "\n",
    "        print(\" Missing values filled\")\n",
    "\n",
    "    def reorder_columns(self):\n",
    "        self.validation_df = self.validation_df.select(*[col for col in self.expected_columns if col in self.validation_df.columns])\n",
    "        self.test_df = self.test_df.select(*[col for col in self.expected_columns if col in self.test_df.columns])\n",
    "        print(\"Columns reordered\")\n",
    "\n",
    "    def save_to_csv(self, validation_path, test_path):\n",
    "        self.validation_df.coalesce(1).write.csv(validation_path, header=True, mode='overwrite', emptyValue=\"\")\n",
    "        self.test_df.coalesce(1).write.csv(test_path, header=True, mode='overwrite', emptyValue=\"\")\n",
    "        print(\"Final validation and test data saved!\")\n",
    "\n",
    "    def process(self, validation_path, test_path):\n",
    "        self.add_missing_columns()\n",
    "        self.fill_missing_values()\n",
    "        self.reorder_columns()\n",
    "        self.save_to_csv(validation_path, test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns added\n",
      " Missing values filled\n",
      "Columns reordered\n",
      "Final validation and test data saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "processor = DataPreprocessor(validation_df, test_df)\n",
    "\n",
    "#save\n",
    "processor.process(\n",
    "    validation_path='/Users/bognarlili/Downloads/new_validation.csv',\n",
    "    test_path='/Users/bognarlili/Downloads/new_test.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the numeric variables to the form required for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idk\n",
    "feature_cols = ['numVotes', 'year', 'tomatometer_status', 'tomatometer_rating', \n",
    "                'audience_status', 'audience_rating', 'like_count']\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "train_data = assembler.transform(train_df)\n",
    "validation_data = assembler.transform(validation_df)\n",
    "test_data = assembler.transform(test_df)\n",
    "\n",
    "### model \n",
    "\n",
    "#generate predictions\n",
    "validation_preds = model.transform(validation_data)\n",
    "test_preds = model.transform(test_data)\n",
    "\n",
    "# predictions to (True/False)\n",
    "validation_results = validation_preds.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
    "test_results = test_preds.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#string\n",
    "validation_results = [\"True\" if pred == 1.0 else \"False\" for pred in validation_results]\n",
    "test_results = [\"True\" if pred == 1.0 else \"False\" for pred in test_results]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "anaconda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
